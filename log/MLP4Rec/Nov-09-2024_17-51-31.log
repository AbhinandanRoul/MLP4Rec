Sat 09 Nov 2024 17:51:31 INFO  
General Hyper Parameters:
gpu_id = 0
use_gpu = True
seed = 2022
state = INFO
reproducibility = True
data_path = dataset/beauty
checkpoint_dir = saved
show_progress = True
save_dataset = False
save_dataloaders = False

Training Hyper Parameters:
epochs = 100
train_batch_size = 256
learner = adam
learning_rate = 0.0001
neg_sampling = None
eval_step = 1
stopping_step = 10
clip_grad_norm = None
weight_decay = 0.0
loss_decimal_place = 4

Evaluation Hyper Parameters:
eval_args = {'split': {'LS': 'valid_and_test'}, 'order': 'TO', 'mode': 'pop100', 'group_by': 'user'}
repeatable = True
metrics = ['Recall', 'MRR', 'NDCG', 'Hit', 'Precision']
topk = [10]
valid_metric = MRR@10
valid_metric_bigger = True
eval_batch_size = 512
metric_decimal_place = 4

Dataset Hyper Parameters:
field_separator = 	
seq_separator =  
USER_ID_FIELD = user_id
ITEM_ID_FIELD = item_id
RATING_FIELD = rating
TIME_FIELD = timestamp
seq_len = None
LABEL_FIELD = rating
threshold = None
NEG_PREFIX = neg_
load_col = {'inter': ['user_id', 'item_id', 'rating', 'timestamp'], 'item': ['item_id', 'sales_rank', 'categories', 'price', 'brand']}
unload_col = None
unused_col = None
additional_feat_suffix = None
rm_dup_inter = None
val_interval = None
filter_inter_by_user_or_item = True
user_inter_num_interval = [5,inf)
item_inter_num_interval = [5,inf)
alias_of_user_id = None
alias_of_item_id = None
alias_of_entity_id = None
alias_of_relation_id = None
preload_weight = None
normalize_field = None
normalize_all = True
ITEM_LIST_LENGTH_FIELD = item_length
LIST_SUFFIX = _list
MAX_ITEM_LIST_LENGTH = 50
POSITION_FIELD = position_id
HEAD_ENTITY_ID_FIELD = head_id
TAIL_ENTITY_ID_FIELD = tail_id
RELATION_ID_FIELD = relation_id
ENTITY_ID_FIELD = entity_id
benchmark_filename = None

Other Hyper Parameters: 
n_layers = 4
hidden_size = 128
hidden_dropout_prob = 0.5
hidden_act = gelu
layer_norm_eps = 1e-12
initializer_range = 0.02
selected_features = ['sales_rank', 'categories', 'price', 'brand']
pooling_mode = mean
loss_type = CE
MODEL_TYPE = ModelType.SEQUENTIAL
MODEL_INPUT_TYPE = InputType.POINTWISE
eval_type = EvaluatorType.RANKING
device = cuda
train_neg_sample_args = {'strategy': 'none'}
eval_neg_sample_args = {'strategy': 'by', 'by': 100, 'distribution': 'popularity'}


Sat 09 Nov 2024 17:51:49 INFO  beauty
The number of users: 22364
Average actions of users: 8.876358270357287
The number of items: 12102
Average actions of items: 16.403768283612923
The number of inters: 198502
The sparsity of the dataset: 99.92665707018277%
Remain Fields: ['user_id', 'item_id', 'rating', 'timestamp', 'sales_rank', 'categories', 'price', 'brand']
Sat 09 Nov 2024 17:51:54 INFO  [Training]: train_batch_size = [256] negative sampling: [None]
Sat 09 Nov 2024 17:51:54 INFO  [Evaluation]: eval_batch_size = [512] eval_args: [{'split': {'LS': 'valid_and_test'}, 'order': 'TO', 'mode': 'pop100', 'group_by': 'user'}]
Sat 09 Nov 2024 17:51:55 INFO  MLP4Rec(
  (item_embedding): Embedding(12102, 128, padding_idx=0)
  (feature_embed_layer): FeatureSeqEmbLayer(
    (token_embedding_table): ModuleDict(
      (item): FMEmbedding(
        (embedding): Embedding(2077, 128)
      )
    )
    (float_embedding_table): ModuleDict(
      (item): Embedding(2, 128)
    )
    (token_seq_embedding_table): ModuleDict(
      (item): ModuleList(
        (0): Embedding(355, 128)
      )
    )
  )
  (sequenceMixer): PreNormResidual(
    (fn): Sequential(
      (0): Conv1d(50, 200, kernel_size=(1,), stride=(1,))
      (1): GELU(approximate='none')
      (2): Dropout(p=0.5, inplace=False)
      (3): Conv1d(200, 50, kernel_size=(1,), stride=(1,))
      (4): Dropout(p=0.5, inplace=False)
    )
    (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
  )
  (channelMixer): PreNormResidual(
    (fn): Sequential(
      (0): Linear(in_features=128, out_features=512, bias=True)
      (1): GELU(approximate='none')
      (2): Dropout(p=0.5, inplace=False)
      (3): Linear(in_features=512, out_features=128, bias=True)
      (4): Dropout(p=0.5, inplace=False)
    )
    (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
  )
  (featureMixer): PreNormResidual(
    (fn): Sequential(
      (0): Conv1d(5, 20, kernel_size=(1,), stride=(1,))
      (1): GELU(approximate='none')
      (2): Dropout(p=0.5, inplace=False)
      (3): Conv1d(20, 5, kernel_size=(1,), stride=(1,))
      (4): Dropout(p=0.5, inplace=False)
    )
    (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
  )
  (layers): ModuleList(
    (0): PreNormResidual(
      (fn): Sequential(
        (0): Conv1d(50, 200, kernel_size=(1,), stride=(1,))
        (1): GELU(approximate='none')
        (2): Dropout(p=0.5, inplace=False)
        (3): Conv1d(200, 50, kernel_size=(1,), stride=(1,))
        (4): Dropout(p=0.5, inplace=False)
      )
      (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
    )
    (1): PreNormResidual(
      (fn): Sequential(
        (0): Linear(in_features=128, out_features=512, bias=True)
        (1): GELU(approximate='none')
        (2): Dropout(p=0.5, inplace=False)
        (3): Linear(in_features=512, out_features=128, bias=True)
        (4): Dropout(p=0.5, inplace=False)
      )
      (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
    )
    (2): PreNormResidual(
      (fn): Sequential(
        (0): Conv1d(50, 200, kernel_size=(1,), stride=(1,))
        (1): GELU(approximate='none')
        (2): Dropout(p=0.5, inplace=False)
        (3): Conv1d(200, 50, kernel_size=(1,), stride=(1,))
        (4): Dropout(p=0.5, inplace=False)
      )
      (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
    )
    (3): PreNormResidual(
      (fn): Sequential(
        (0): Linear(in_features=128, out_features=512, bias=True)
        (1): GELU(approximate='none')
        (2): Dropout(p=0.5, inplace=False)
        (3): Linear(in_features=512, out_features=128, bias=True)
        (4): Dropout(p=0.5, inplace=False)
      )
      (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
    )
    (4): PreNormResidual(
      (fn): Sequential(
        (0): Conv1d(50, 200, kernel_size=(1,), stride=(1,))
        (1): GELU(approximate='none')
        (2): Dropout(p=0.5, inplace=False)
        (3): Conv1d(200, 50, kernel_size=(1,), stride=(1,))
        (4): Dropout(p=0.5, inplace=False)
      )
      (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
    )
    (5): PreNormResidual(
      (fn): Sequential(
        (0): Linear(in_features=128, out_features=512, bias=True)
        (1): GELU(approximate='none')
        (2): Dropout(p=0.5, inplace=False)
        (3): Linear(in_features=512, out_features=128, bias=True)
        (4): Dropout(p=0.5, inplace=False)
      )
      (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
    )
    (6): PreNormResidual(
      (fn): Sequential(
        (0): Conv1d(50, 200, kernel_size=(1,), stride=(1,))
        (1): GELU(approximate='none')
        (2): Dropout(p=0.5, inplace=False)
        (3): Conv1d(200, 50, kernel_size=(1,), stride=(1,))
        (4): Dropout(p=0.5, inplace=False)
      )
      (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
    )
    (7): PreNormResidual(
      (fn): Sequential(
        (0): Linear(in_features=128, out_features=512, bias=True)
        (1): GELU(approximate='none')
        (2): Dropout(p=0.5, inplace=False)
        (3): Linear(in_features=512, out_features=128, bias=True)
        (4): Dropout(p=0.5, inplace=False)
      )
      (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
    )
    (8): PreNormResidual(
      (fn): Sequential(
        (0): Conv1d(50, 200, kernel_size=(1,), stride=(1,))
        (1): GELU(approximate='none')
        (2): Dropout(p=0.5, inplace=False)
        (3): Conv1d(200, 50, kernel_size=(1,), stride=(1,))
        (4): Dropout(p=0.5, inplace=False)
      )
      (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
    )
    (9): PreNormResidual(
      (fn): Sequential(
        (0): Linear(in_features=128, out_features=512, bias=True)
        (1): GELU(approximate='none')
        (2): Dropout(p=0.5, inplace=False)
        (3): Linear(in_features=512, out_features=128, bias=True)
        (4): Dropout(p=0.5, inplace=False)
      )
      (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
    )
  )
  (LayerNorm): LayerNorm((128,), eps=1e-12, elementwise_affine=True)
  (dropout): Dropout(p=0.5, inplace=False)
  (loss_fct): CrossEntropyLoss()
)
Trainable parameters: 2013819
Sat 09 Nov 2024 17:56:21 INFO  epoch 0 training [time: 265.48s, train loss: 4760.7111]
Sat 09 Nov 2024 18:03:46 INFO  epoch 0 evaluating [time: 445.58s, valid_score: 0.027800]
Sat 09 Nov 2024 18:03:46 INFO  valid result: 
recall@10 : 0.0809    mrr@10 : 0.0278    ndcg@10 : 0.04    hit@10 : 0.0809    precision@10 : 0.0081
Sat 09 Nov 2024 18:03:47 INFO  Saving current best: saved/MLP4Rec-Nov-09-2024_17-51-55.pth
Sat 09 Nov 2024 18:08:11 INFO  epoch 1 training [time: 264.37s, train loss: 4559.3445]
Sat 09 Nov 2024 18:15:27 INFO  epoch 1 evaluating [time: 436.19s, valid_score: 0.025000]
Sat 09 Nov 2024 18:15:27 INFO  valid result: 
recall@10 : 0.0735    mrr@10 : 0.025    ndcg@10 : 0.0361    hit@10 : 0.0735    precision@10 : 0.0074
Sat 09 Nov 2024 18:20:00 INFO  epoch 2 training [time: 273.25s, train loss: 4531.6045]
Sat 09 Nov 2024 18:27:16 INFO  epoch 2 evaluating [time: 435.92s, valid_score: 0.024900]
Sat 09 Nov 2024 18:27:16 INFO  valid result: 
recall@10 : 0.0738    mrr@10 : 0.0249    ndcg@10 : 0.0362    hit@10 : 0.0738    precision@10 : 0.0074
Sat 09 Nov 2024 18:31:46 INFO  epoch 3 training [time: 269.54s, train loss: 4500.3760]
Sat 09 Nov 2024 18:39:07 INFO  epoch 3 evaluating [time: 441.16s, valid_score: 0.034900]
Sat 09 Nov 2024 18:39:07 INFO  valid result: 
recall@10 : 0.1166    mrr@10 : 0.0349    ndcg@10 : 0.0536    hit@10 : 0.1166    precision@10 : 0.0117
Sat 09 Nov 2024 18:39:08 INFO  Saving current best: saved/MLP4Rec-Nov-09-2024_17-51-55.pth
Sat 09 Nov 2024 18:43:33 INFO  epoch 4 training [time: 264.70s, train loss: 4383.7270]
Sat 09 Nov 2024 18:50:47 INFO  epoch 4 evaluating [time: 434.59s, valid_score: 0.043900]
Sat 09 Nov 2024 18:50:47 INFO  valid result: 
recall@10 : 0.1487    mrr@10 : 0.0439    ndcg@10 : 0.0678    hit@10 : 0.1487    precision@10 : 0.0149
Sat 09 Nov 2024 18:50:48 INFO  Saving current best: saved/MLP4Rec-Nov-09-2024_17-51-55.pth
Sat 09 Nov 2024 18:55:21 INFO  epoch 5 training [time: 273.58s, train loss: 4305.8078]
Sat 09 Nov 2024 19:02:38 INFO  epoch 5 evaluating [time: 436.63s, valid_score: 0.058200]
Sat 09 Nov 2024 19:02:38 INFO  valid result: 
recall@10 : 0.1787    mrr@10 : 0.0582    ndcg@10 : 0.0859    hit@10 : 0.1787    precision@10 : 0.0179
Sat 09 Nov 2024 19:02:38 INFO  Saving current best: saved/MLP4Rec-Nov-09-2024_17-51-55.pth
Sat 09 Nov 2024 19:07:12 INFO  epoch 6 training [time: 274.01s, train loss: 4213.7001]
Sat 09 Nov 2024 19:14:28 INFO  epoch 6 evaluating [time: 435.85s, valid_score: 0.081700]
Sat 09 Nov 2024 19:14:28 INFO  valid result: 
recall@10 : 0.2358    mrr@10 : 0.0817    ndcg@10 : 0.1172    hit@10 : 0.2358    precision@10 : 0.0236
Sat 09 Nov 2024 19:14:28 INFO  Saving current best: saved/MLP4Rec-Nov-09-2024_17-51-55.pth
Sat 09 Nov 2024 19:18:52 INFO  epoch 7 training [time: 264.63s, train loss: 4116.4980]
Sat 09 Nov 2024 19:26:08 INFO  epoch 7 evaluating [time: 435.77s, valid_score: 0.100500]
Sat 09 Nov 2024 19:26:08 INFO  valid result: 
recall@10 : 0.2819    mrr@10 : 0.1005    ndcg@10 : 0.1424    hit@10 : 0.2819    precision@10 : 0.0282
Sat 09 Nov 2024 19:26:08 INFO  Saving current best: saved/MLP4Rec-Nov-09-2024_17-51-55.pth
Sat 09 Nov 2024 19:30:42 INFO  epoch 8 training [time: 273.36s, train loss: 4038.7397]
Sat 09 Nov 2024 19:37:58 INFO  epoch 8 evaluating [time: 436.20s, valid_score: 0.113000]
Sat 09 Nov 2024 19:37:58 INFO  valid result: 
recall@10 : 0.3121    mrr@10 : 0.113    ndcg@10 : 0.1591    hit@10 : 0.3121    precision@10 : 0.0312
Sat 09 Nov 2024 19:37:58 INFO  Saving current best: saved/MLP4Rec-Nov-09-2024_17-51-55.pth
Sat 09 Nov 2024 19:42:32 INFO  epoch 9 training [time: 273.99s, train loss: 3972.4986]
Sat 09 Nov 2024 19:49:49 INFO  epoch 9 evaluating [time: 436.61s, valid_score: 0.127700]
Sat 09 Nov 2024 19:49:49 INFO  valid result: 
recall@10 : 0.3339    mrr@10 : 0.1277    ndcg@10 : 0.1756    hit@10 : 0.3339    precision@10 : 0.0334
Sat 09 Nov 2024 19:49:49 INFO  Saving current best: saved/MLP4Rec-Nov-09-2024_17-51-55.pth
Sat 09 Nov 2024 19:54:13 INFO  epoch 10 training [time: 264.84s, train loss: 3910.5055]
Sat 09 Nov 2024 20:01:32 INFO  epoch 10 evaluating [time: 438.35s, valid_score: 0.142900]
Sat 09 Nov 2024 20:01:32 INFO  valid result: 
recall@10 : 0.3553    mrr@10 : 0.1429    ndcg@10 : 0.1924    hit@10 : 0.3553    precision@10 : 0.0355
Sat 09 Nov 2024 20:01:32 INFO  Saving current best: saved/MLP4Rec-Nov-09-2024_17-51-55.pth
Sat 09 Nov 2024 20:06:03 INFO  epoch 11 training [time: 271.23s, train loss: 3849.2849]
Sat 09 Nov 2024 20:13:18 INFO  epoch 11 evaluating [time: 434.42s, valid_score: 0.154200]
Sat 09 Nov 2024 20:13:18 INFO  valid result: 
recall@10 : 0.3735    mrr@10 : 0.1542    ndcg@10 : 0.2054    hit@10 : 0.3735    precision@10 : 0.0373
Sat 09 Nov 2024 20:13:18 INFO  Saving current best: saved/MLP4Rec-Nov-09-2024_17-51-55.pth
Sat 09 Nov 2024 20:17:51 INFO  epoch 12 training [time: 273.60s, train loss: 3792.5128]
Sat 09 Nov 2024 20:25:07 INFO  epoch 12 evaluating [time: 436.06s, valid_score: 0.165200]
Sat 09 Nov 2024 20:25:07 INFO  valid result: 
recall@10 : 0.3889    mrr@10 : 0.1652    ndcg@10 : 0.2174    hit@10 : 0.3889    precision@10 : 0.0389
Sat 09 Nov 2024 20:25:08 INFO  Saving current best: saved/MLP4Rec-Nov-09-2024_17-51-55.pth
Sat 09 Nov 2024 20:29:32 INFO  epoch 13 training [time: 264.62s, train loss: 3735.5924]
Sat 09 Nov 2024 20:36:58 INFO  epoch 13 evaluating [time: 445.93s, valid_score: 0.176900]
Sat 09 Nov 2024 20:36:58 INFO  valid result: 
recall@10 : 0.4024    mrr@10 : 0.1769    ndcg@10 : 0.2298    hit@10 : 0.4024    precision@10 : 0.0402
Sat 09 Nov 2024 20:36:59 INFO  Saving current best: saved/MLP4Rec-Nov-09-2024_17-51-55.pth
Sat 09 Nov 2024 20:41:24 INFO  epoch 14 training [time: 264.53s, train loss: 3683.1139]
Sat 09 Nov 2024 20:48:40 INFO  epoch 14 evaluating [time: 436.35s, valid_score: 0.186400]
Sat 09 Nov 2024 20:48:40 INFO  valid result: 
recall@10 : 0.4135    mrr@10 : 0.1864    ndcg@10 : 0.2397    hit@10 : 0.4135    precision@10 : 0.0414
Sat 09 Nov 2024 20:48:41 INFO  Saving current best: saved/MLP4Rec-Nov-09-2024_17-51-55.pth
Sat 09 Nov 2024 20:53:15 INFO  epoch 15 training [time: 273.46s, train loss: 3632.3233]
Sat 09 Nov 2024 21:00:30 INFO  epoch 15 evaluating [time: 435.24s, valid_score: 0.193600]
Sat 09 Nov 2024 21:00:30 INFO  valid result: 
recall@10 : 0.4247    mrr@10 : 0.1936    ndcg@10 : 0.2478    hit@10 : 0.4247    precision@10 : 0.0425
Sat 09 Nov 2024 21:00:30 INFO  Saving current best: saved/MLP4Rec-Nov-09-2024_17-51-55.pth
Sat 09 Nov 2024 21:05:04 INFO  epoch 16 training [time: 273.88s, train loss: 3583.4780]
Sat 09 Nov 2024 21:12:20 INFO  epoch 16 evaluating [time: 436.11s, valid_score: 0.202000]
Sat 09 Nov 2024 21:12:20 INFO  valid result: 
recall@10 : 0.4342    mrr@10 : 0.202    ndcg@10 : 0.2565    hit@10 : 0.4342    precision@10 : 0.0434
Sat 09 Nov 2024 21:12:21 INFO  Saving current best: saved/MLP4Rec-Nov-09-2024_17-51-55.pth
Sat 09 Nov 2024 21:16:45 INFO  epoch 17 training [time: 264.74s, train loss: 3534.2764]
Sat 09 Nov 2024 21:24:02 INFO  epoch 17 evaluating [time: 436.42s, valid_score: 0.208100]
Sat 09 Nov 2024 21:24:02 INFO  valid result: 
recall@10 : 0.441    mrr@10 : 0.2081    ndcg@10 : 0.2628    hit@10 : 0.441    precision@10 : 0.0441
Sat 09 Nov 2024 21:24:02 INFO  Saving current best: saved/MLP4Rec-Nov-09-2024_17-51-55.pth
Sat 09 Nov 2024 21:28:35 INFO  epoch 18 training [time: 273.38s, train loss: 3486.3830]
Sat 09 Nov 2024 21:35:52 INFO  epoch 18 evaluating [time: 436.47s, valid_score: 0.213200]
Sat 09 Nov 2024 21:35:52 INFO  valid result: 
recall@10 : 0.4472    mrr@10 : 0.2132    ndcg@10 : 0.2683    hit@10 : 0.4472    precision@10 : 0.0447
Sat 09 Nov 2024 21:35:52 INFO  Saving current best: saved/MLP4Rec-Nov-09-2024_17-51-55.pth
Sat 09 Nov 2024 21:40:27 INFO  epoch 19 training [time: 275.03s, train loss: 3439.9428]
Sat 09 Nov 2024 21:45:57 INFO  epoch 19 evaluating [time: 329.60s, valid_score: 0.219300]
Sat 09 Nov 2024 21:45:57 INFO  valid result: 
recall@10 : 0.4515    mrr@10 : 0.2193    ndcg@10 : 0.274    hit@10 : 0.4515    precision@10 : 0.0452
Sat 09 Nov 2024 21:45:57 INFO  Saving current best: saved/MLP4Rec-Nov-09-2024_17-51-55.pth
Sat 09 Nov 2024 21:47:57 INFO  epoch 20 training [time: 120.51s, train loss: 3394.3712]
Sat 09 Nov 2024 21:53:27 INFO  epoch 20 evaluating [time: 329.52s, valid_score: 0.224000]
Sat 09 Nov 2024 21:53:27 INFO  valid result: 
recall@10 : 0.4549    mrr@10 : 0.224    ndcg@10 : 0.2784    hit@10 : 0.4549    precision@10 : 0.0455
Sat 09 Nov 2024 21:53:27 INFO  Saving current best: saved/MLP4Rec-Nov-09-2024_17-51-55.pth
Sat 09 Nov 2024 21:55:27 INFO  epoch 21 training [time: 120.17s, train loss: 3350.2116]
Sat 09 Nov 2024 22:00:56 INFO  epoch 21 evaluating [time: 329.55s, valid_score: 0.231000]
Sat 09 Nov 2024 22:00:56 INFO  valid result: 
recall@10 : 0.4609    mrr@10 : 0.231    ndcg@10 : 0.2852    hit@10 : 0.4609    precision@10 : 0.0461
Sat 09 Nov 2024 22:00:57 INFO  Saving current best: saved/MLP4Rec-Nov-09-2024_17-51-55.pth
Sat 09 Nov 2024 22:02:57 INFO  epoch 22 training [time: 120.38s, train loss: 3306.4262]
Sat 09 Nov 2024 22:08:27 INFO  epoch 22 evaluating [time: 329.58s, valid_score: 0.230500]
Sat 09 Nov 2024 22:08:27 INFO  valid result: 
recall@10 : 0.4628    mrr@10 : 0.2305    ndcg@10 : 0.2853    hit@10 : 0.4628    precision@10 : 0.0463
Sat 09 Nov 2024 22:10:27 INFO  epoch 23 training [time: 120.41s, train loss: 3263.4811]
Sat 09 Nov 2024 22:15:57 INFO  epoch 23 evaluating [time: 329.58s, valid_score: 0.236200]
Sat 09 Nov 2024 22:15:57 INFO  valid result: 
recall@10 : 0.4665    mrr@10 : 0.2362    ndcg@10 : 0.2905    hit@10 : 0.4665    precision@10 : 0.0467
Sat 09 Nov 2024 22:15:57 INFO  Saving current best: saved/MLP4Rec-Nov-09-2024_17-51-55.pth
Sat 09 Nov 2024 22:17:57 INFO  epoch 24 training [time: 120.13s, train loss: 3221.4758]
Sat 09 Nov 2024 22:23:26 INFO  epoch 24 evaluating [time: 329.62s, valid_score: 0.236000]
Sat 09 Nov 2024 22:23:26 INFO  valid result: 
recall@10 : 0.4645    mrr@10 : 0.236    ndcg@10 : 0.29    hit@10 : 0.4645    precision@10 : 0.0465
Sat 09 Nov 2024 22:25:27 INFO  epoch 25 training [time: 120.30s, train loss: 3182.3749]
Sat 09 Nov 2024 22:30:56 INFO  epoch 25 evaluating [time: 329.56s, valid_score: 0.240200]
Sat 09 Nov 2024 22:30:56 INFO  valid result: 
recall@10 : 0.4695    mrr@10 : 0.2402    ndcg@10 : 0.2944    hit@10 : 0.4695    precision@10 : 0.0469
Sat 09 Nov 2024 22:30:56 INFO  Saving current best: saved/MLP4Rec-Nov-09-2024_17-51-55.pth
Sat 09 Nov 2024 22:32:57 INFO  epoch 26 training [time: 120.22s, train loss: 3142.6532]
Sat 09 Nov 2024 22:38:26 INFO  epoch 26 evaluating [time: 329.50s, valid_score: 0.241900]
Sat 09 Nov 2024 22:38:26 INFO  valid result: 
recall@10 : 0.468    mrr@10 : 0.2419    ndcg@10 : 0.2953    hit@10 : 0.468    precision@10 : 0.0468
Sat 09 Nov 2024 22:38:26 INFO  Saving current best: saved/MLP4Rec-Nov-09-2024_17-51-55.pth
Sat 09 Nov 2024 22:40:26 INFO  epoch 27 training [time: 120.22s, train loss: 3101.8240]
Sat 09 Nov 2024 22:45:56 INFO  epoch 27 evaluating [time: 329.53s, valid_score: 0.241700]
Sat 09 Nov 2024 22:45:56 INFO  valid result: 
recall@10 : 0.4676    mrr@10 : 0.2417    ndcg@10 : 0.2951    hit@10 : 0.4676    precision@10 : 0.0468
Sat 09 Nov 2024 22:47:56 INFO  epoch 28 training [time: 120.33s, train loss: 3063.9945]
Sat 09 Nov 2024 22:53:26 INFO  epoch 28 evaluating [time: 329.51s, valid_score: 0.245100]
Sat 09 Nov 2024 22:53:26 INFO  valid result: 
recall@10 : 0.4684    mrr@10 : 0.2451    ndcg@10 : 0.2978    hit@10 : 0.4684    precision@10 : 0.0468
Sat 09 Nov 2024 22:53:26 INFO  Saving current best: saved/MLP4Rec-Nov-09-2024_17-51-55.pth
Sat 09 Nov 2024 22:55:26 INFO  epoch 29 training [time: 120.18s, train loss: 3027.1992]
Sat 09 Nov 2024 23:00:56 INFO  epoch 29 evaluating [time: 329.56s, valid_score: 0.241600]
Sat 09 Nov 2024 23:00:56 INFO  valid result: 
recall@10 : 0.4664    mrr@10 : 0.2416    ndcg@10 : 0.2947    hit@10 : 0.4664    precision@10 : 0.0466
Sat 09 Nov 2024 23:02:56 INFO  epoch 30 training [time: 120.42s, train loss: 2989.8773]
Sat 09 Nov 2024 23:08:26 INFO  epoch 30 evaluating [time: 329.52s, valid_score: 0.242000]
Sat 09 Nov 2024 23:08:26 INFO  valid result: 
recall@10 : 0.4662    mrr@10 : 0.242    ndcg@10 : 0.2949    hit@10 : 0.4662    precision@10 : 0.0466
Sat 09 Nov 2024 23:10:26 INFO  epoch 31 training [time: 120.37s, train loss: 2953.7373]
Sat 09 Nov 2024 23:15:55 INFO  epoch 31 evaluating [time: 329.57s, valid_score: 0.241700]
Sat 09 Nov 2024 23:15:55 INFO  valid result: 
recall@10 : 0.4649    mrr@10 : 0.2417    ndcg@10 : 0.2944    hit@10 : 0.4649    precision@10 : 0.0465
Sat 09 Nov 2024 23:17:56 INFO  epoch 32 training [time: 120.46s, train loss: 2919.8003]
Sat 09 Nov 2024 23:23:26 INFO  epoch 32 evaluating [time: 329.63s, valid_score: 0.244000]
Sat 09 Nov 2024 23:23:26 INFO  valid result: 
recall@10 : 0.4622    mrr@10 : 0.244    ndcg@10 : 0.2956    hit@10 : 0.4622    precision@10 : 0.0462
Sat 09 Nov 2024 23:25:26 INFO  epoch 33 training [time: 120.74s, train loss: 2886.1442]
Sat 09 Nov 2024 23:30:56 INFO  epoch 33 evaluating [time: 329.63s, valid_score: 0.241800]
Sat 09 Nov 2024 23:30:56 INFO  valid result: 
recall@10 : 0.4628    mrr@10 : 0.2418    ndcg@10 : 0.294    hit@10 : 0.4628    precision@10 : 0.0463
Sat 09 Nov 2024 23:32:56 INFO  epoch 34 training [time: 120.45s, train loss: 2852.7328]
Sat 09 Nov 2024 23:38:26 INFO  epoch 34 evaluating [time: 329.59s, valid_score: 0.243800]
Sat 09 Nov 2024 23:38:26 INFO  valid result: 
recall@10 : 0.464    mrr@10 : 0.2438    ndcg@10 : 0.2958    hit@10 : 0.464    precision@10 : 0.0464
Sat 09 Nov 2024 23:40:26 INFO  epoch 35 training [time: 120.42s, train loss: 2821.6220]
Sat 09 Nov 2024 23:45:56 INFO  epoch 35 evaluating [time: 329.54s, valid_score: 0.241900]
Sat 09 Nov 2024 23:45:56 INFO  valid result: 
recall@10 : 0.463    mrr@10 : 0.2419    ndcg@10 : 0.2941    hit@10 : 0.463    precision@10 : 0.0463
Sat 09 Nov 2024 23:47:57 INFO  epoch 36 training [time: 120.63s, train loss: 2790.6507]
Sat 09 Nov 2024 23:53:26 INFO  epoch 36 evaluating [time: 329.58s, valid_score: 0.242300]
Sat 09 Nov 2024 23:53:26 INFO  valid result: 
recall@10 : 0.4613    mrr@10 : 0.2423    ndcg@10 : 0.2941    hit@10 : 0.4613    precision@10 : 0.0461
Sat 09 Nov 2024 23:55:27 INFO  epoch 37 training [time: 120.40s, train loss: 2761.9931]
Sun 10 Nov 2024 00:00:56 INFO  epoch 37 evaluating [time: 329.63s, valid_score: 0.242800]
Sun 10 Nov 2024 00:00:56 INFO  valid result: 
recall@10 : 0.4566    mrr@10 : 0.2428    ndcg@10 : 0.2933    hit@10 : 0.4566    precision@10 : 0.0457
Sun 10 Nov 2024 00:02:57 INFO  epoch 38 training [time: 120.42s, train loss: 2731.8148]
Sun 10 Nov 2024 00:08:26 INFO  epoch 38 evaluating [time: 329.61s, valid_score: 0.236500]
Sun 10 Nov 2024 00:08:26 INFO  valid result: 
recall@10 : 0.4522    mrr@10 : 0.2365    ndcg@10 : 0.2874    hit@10 : 0.4522    precision@10 : 0.0452
Sun 10 Nov 2024 00:10:27 INFO  epoch 39 training [time: 120.39s, train loss: 2704.2733]
Sun 10 Nov 2024 00:15:56 INFO  epoch 39 evaluating [time: 329.62s, valid_score: 0.236700]
Sun 10 Nov 2024 00:15:56 INFO  valid result: 
recall@10 : 0.4496    mrr@10 : 0.2367    ndcg@10 : 0.2869    hit@10 : 0.4496    precision@10 : 0.045
Sun 10 Nov 2024 00:15:56 INFO  Finished training, best eval result in epoch 28
Sun 10 Nov 2024 00:15:56 INFO  Loading model structure and parameters from saved/MLP4Rec-Nov-09-2024_17-51-55.pth
Sun 10 Nov 2024 00:21:26 INFO  best valid : OrderedDict({'recall@10': np.float64(0.4684), 'mrr@10': np.float64(0.2451), 'ndcg@10': np.float64(0.2978), 'hit@10': np.float64(0.4684), 'precision@10': np.float64(0.0468)})
Sun 10 Nov 2024 00:21:26 INFO  test result: OrderedDict({'recall@10': np.float64(0.4389), 'mrr@10': np.float64(0.2182), 'ndcg@10': np.float64(0.2702), 'hit@10': np.float64(0.4389), 'precision@10': np.float64(0.0439)})
